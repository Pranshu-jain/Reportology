{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "\n",
    "filename = 'glove.6B.50d.txt'\n",
    "def loadGloVe(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    file = open(filename,'r')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded GloVe!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "vocab,embd = loadGloVe(filename)\n",
    "\n",
    "embedding = np.asarray(embd)\n",
    "embedding = embedding.astype(np.float32)\n",
    "\n",
    "word_vec_dim = len(embedding[0])\n",
    "#Pre-trained GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_nearest_neighbour(x):\n",
    "    #returns array in embedding that's most similar (in terms of cosine similarity) to x\n",
    "        \n",
    "    xdoty = np.multiply(embedding,x)\n",
    "    xdoty = np.sum(xdoty,1)\n",
    "    xlen = np.square(x)\n",
    "    xlen = np.sum(xlen,0)\n",
    "    xlen = np.sqrt(xlen)\n",
    "    ylen = np.square(embedding)\n",
    "    ylen = np.sum(ylen,1)\n",
    "    ylen = np.sqrt(ylen)\n",
    "    xlenylen = np.multiply(xlen,ylen)\n",
    "    cosine_similarities = np.divide(xdoty,xlenylen)\n",
    "\n",
    "    return embedding[np.argmax(cosine_similarities)]\n",
    "\n",
    "\n",
    "def word2vec(word):  # converts a given word into its vector representation\n",
    "    if word in vocab:\n",
    "        return embedding[vocab.index(word)]\n",
    "    else:\n",
    "        return embedding[vocab.index('unk')]\n",
    "\n",
    "def vec2word(vec):   # converts a given vector representation into the represented word \n",
    "    for x in range(0, len(embedding)):\n",
    "        if np.array_equal(embedding[x],np.asarray(vec)):\n",
    "            return vocab[x]\n",
    "    return vec2word(np_nearest_neighbour(np.asarray(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open ('vec_summaries', 'rb') as fp:\n",
    "    vec_summaries = pickle.load(fp)\n",
    "\n",
    "with open ('vec_texts', 'rb') as fp:\n",
    "    vec_texts = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('vocab_limit', 'rb') as fp:\n",
    "    vocab_limit = pickle.load(fp)\n",
    "\n",
    "with open ('embd_limit', 'rb') as fp:\n",
    "    embd_limit = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_limit.append('<SOS>')\n",
    "embd_limit.append(np.zeros((word_vec_dim),dtype=np.float32))\n",
    "\n",
    "SOS = embd_limit[vocab_limit.index('<SOS>')]\n",
    "\n",
    "np_embd_limit = np.asarray(embd_limit,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset with summary length beyond  7\n",
      ":  59.894459102902374\n",
      "Percentage of dataset with text length less that window size:  1.8469656992084433\n",
      "Percentage of dataset with text length more than  80\n",
      ":  87.33509234828496\n"
     ]
    }
   ],
   "source": [
    "#DIAGNOSIS\n",
    "\n",
    "count = 0\n",
    "\n",
    "LEN = 7\n",
    "\n",
    "for summary in vec_summaries:\n",
    "    if len(summary)-1>LEN:\n",
    "        count = count + 1\n",
    "print(\"Percentage of dataset with summary length beyond \", str(LEN))\n",
    "print(\": \", str((count/len(vec_summaries))*100))\n",
    "\n",
    "count = 0\n",
    "\n",
    "D = 10 \n",
    "\n",
    "window_size = 2*D+1\n",
    "\n",
    "for text in vec_texts:\n",
    "    if len(text)<window_size+1:\n",
    "        count = count + 1\n",
    "print(\"Percentage of dataset with text length less that window size: \",str((count/len(vec_texts))*100))\n",
    "\n",
    "count = 0\n",
    "\n",
    "LEN = 80\n",
    "\n",
    "for text in vec_texts:\n",
    "    if len(text)>LEN:\n",
    "        count = count + 1\n",
    "print(\"Percentage of dataset with text length more than \", str(LEN))\n",
    "print(\": \", str((count/len(vec_texts))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SUMMARY_LEN = 7\n",
    "MAX_TEXT_LEN = 80\n",
    "\n",
    "#D is a major hyperparameters. Windows size for local attention will be 2*D+1\n",
    "D = 10\n",
    "\n",
    "window_size = 2*D+1\n",
    "\n",
    "#REMOVE DATA WHOSE SUMMARIES ARE TOO BIG\n",
    "#OR WHOSE TEXT LENGTH IS TOO BIG\n",
    "#OR WHOSE TEXT LENGTH IS SMALLED THAN WINDOW SIZE\n",
    "\n",
    "vec_summaries_reduced = []\n",
    "vec_texts_reduced = []\n",
    "\n",
    "i = 0\n",
    "for summary in vec_summaries:\n",
    "    if len(summary)-1<=MAX_SUMMARY_LEN and len(vec_texts[i])>=window_size and len(vec_texts[i])<=MAX_TEXT_LEN:\n",
    "        vec_summaries_reduced.append(summary)\n",
    "        vec_texts_reduced.append(vec_texts[i])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_len = int((.7)*len(vec_summaries_reduced))\n",
    "\n",
    "train_texts = vec_texts_reduced[0:train_len]\n",
    "train_summaries = vec_summaries_reduced[0:train_len]\n",
    "\n",
    "val_len = int((.15)*len(vec_summaries_reduced))\n",
    "\n",
    "val_texts = vec_texts_reduced[train_len:train_len+val_len]\n",
    "val_summaries = vec_summaries_reduced[train_len:train_len+val_len]\n",
    "\n",
    "test_texts = vec_texts_reduced[train_len+val_len:len(vec_summaries_reduced)]\n",
    "test_summaries = vec_summaries_reduced[train_len+val_len:len(vec_summaries_reduced)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print (train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_out(output_text):\n",
    "    output_len = len(output_text)\n",
    "    transformed_output = np.zeros([output_len],dtype=np.int32)\n",
    "    for i in range(0,output_len):\n",
    "        transformed_output[i] = vocab_limit.index(vec2word(output_text[i]))\n",
    "    return transformed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some MORE hyperparameters and other stuffs\n",
    "\n",
    "hidden_size = 500\n",
    "learning_rate = 0.003\n",
    "K = 15\n",
    "vocab_len = len(vocab_limit)\n",
    "training_iters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#placeholders\n",
    "tf_text = tf.placeholder(tf.float32, [None,word_vec_dim])\n",
    "tf_seq_len = tf.placeholder(tf.int32)\n",
    "tf_summary = tf.placeholder(tf.int32,[None])\n",
    "tf_output_len = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_encoder(inp,hidden,cell,\n",
    "                    wf,uf,bf,\n",
    "                    wi,ui,bi,\n",
    "                    wo,uo,bo,\n",
    "                    wc,uc,bc,\n",
    "                    Wattention,seq_len,inp_dim):\n",
    "\n",
    "    Wattention = tf.nn.softmax(Wattention,0)\n",
    "    hidden_forward = tf.TensorArray(size=seq_len,dtype=tf.float32)\n",
    "    \n",
    "    hidden_residuals = tf.TensorArray(size=K,dynamic_size=True,dtype=tf.float32,clear_after_read=False)\n",
    "    hidden_residuals = hidden_residuals.unstack(tf.zeros([K,hidden_size],dtype=tf.float32))\n",
    "    \n",
    "    i=0\n",
    "    j=K\n",
    "    \n",
    "    def cond(i,j,hidden,cell,hidden_forward,hidden_residuals):\n",
    "        return i < seq_len\n",
    "    \n",
    "    def body(i,j,hidden,cell,hidden_forward,hidden_residuals):\n",
    "        \n",
    "        x = tf.reshape(inp[i],[1,inp_dim])\n",
    "        \n",
    "        hidden_residuals_stack = hidden_residuals.stack()\n",
    "        \n",
    "        RRA = tf.reduce_sum(tf.multiply(hidden_residuals_stack[j-K:j],Wattention),0)\n",
    "        RRA = tf.reshape(RRA,[1,hidden_size])\n",
    "        \n",
    "        # LSTM with RRA\n",
    "        fg = tf.sigmoid( tf.matmul(x,wf) + tf.matmul(hidden,uf) + bf)\n",
    "        ig = tf.sigmoid( tf.matmul(x,wi) + tf.matmul(hidden,ui) + bi)\n",
    "        og = tf.sigmoid( tf.matmul(x,wo) + tf.matmul(hidden,uo) + bo)\n",
    "        cell = tf.multiply(fg,cell) + tf.multiply(ig,tf.sigmoid( tf.matmul(x,wc) + tf.matmul(hidden,uc) + bc))\n",
    "        hidden = tf.multiply(og,tf.tanh(cell+RRA))\n",
    "        \n",
    "        hidden_residuals = tf.cond(tf.equal(j,seq_len-1+K),\n",
    "                                   lambda: hidden_residuals,\n",
    "                                   lambda: hidden_residuals.write(j,tf.reshape(hidden,[hidden_size])))\n",
    "\n",
    "        hidden_forward = hidden_forward.write(i,tf.reshape(hidden,[hidden_size]))\n",
    "        \n",
    "        return i+1,j+1,hidden,cell,hidden_forward,hidden_residuals\n",
    "    \n",
    "    _,_,_,_,hidden_forward,hidden_residuals = tf.while_loop(cond,body,[i,j,hidden,cell,hidden_forward,hidden_residuals])\n",
    "    \n",
    "    hidden_residuals.close().mark_used()\n",
    "    \n",
    "    return hidden_forward.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_encoder(inp,hidden,cell,\n",
    "                     wf,uf,bf,\n",
    "                     wi,ui,bi,\n",
    "                     wo,uo,bo,\n",
    "                     wc,uc,bc,\n",
    "                     Wattention,seq_len,inp_dim):\n",
    "    \n",
    "    Wattention = tf.nn.softmax(Wattention,0)\n",
    "    hidden_backward = tf.TensorArray(size=seq_len,dtype=tf.float32)\n",
    "    \n",
    "    hidden_residuals = tf.TensorArray(size=K,dynamic_size=True,dtype=tf.float32,clear_after_read=False)\n",
    "    hidden_residuals = hidden_residuals.unstack(tf.zeros([K,hidden_size],dtype=tf.float32))\n",
    "    \n",
    "    i=seq_len-1\n",
    "    j=K\n",
    "    \n",
    "    def cond(i,j,hidden,cell,hidden_backward,hidden_residuals):\n",
    "        return i > -1\n",
    "    \n",
    "    def body(i,j,hidden,cell,hidden_backward,hidden_residuals):\n",
    "        \n",
    "        x = tf.reshape(inp[i],[1,inp_dim])\n",
    "        \n",
    "        hidden_residuals_stack = hidden_residuals.stack()\n",
    "        \n",
    "        RRA = tf.reduce_sum(tf.multiply(hidden_residuals_stack[j-K:j],Wattention),0)\n",
    "        RRA = tf.reshape(RRA,[1,hidden_size])\n",
    "        \n",
    "        # LSTM with RRA\n",
    "        fg = tf.sigmoid( tf.matmul(x,wf) + tf.matmul(hidden,uf) + bf)\n",
    "        ig = tf.sigmoid( tf.matmul(x,wi) + tf.matmul(hidden,ui) + bi)\n",
    "        og = tf.sigmoid( tf.matmul(x,wo) + tf.matmul(hidden,uo) + bo)\n",
    "        cell = tf.multiply(fg,cell) + tf.multiply(ig,tf.sigmoid( tf.matmul(x,wc) + tf.matmul(hidden,uc) + bc))\n",
    "        hidden = tf.multiply(og,tf.tanh(cell+RRA))\n",
    "\n",
    "        hidden_residuals = tf.cond(tf.equal(j,seq_len-1+K),\n",
    "                                   lambda: hidden_residuals,\n",
    "                                   lambda: hidden_residuals.write(j,tf.reshape(hidden,[hidden_size])))\n",
    "        \n",
    "        hidden_backward = hidden_backward.write(i,tf.reshape(hidden,[hidden_size]))\n",
    "        \n",
    "        return i-1,j+1,hidden,cell,hidden_backward,hidden_residuals\n",
    "    \n",
    "    _,_,_,_,hidden_backward,hidden_residuals = tf.while_loop(cond,body,[i,j,hidden,cell,hidden_backward,hidden_residuals])\n",
    "\n",
    "    hidden_residuals.close().mark_used()\n",
    "    \n",
    "    return hidden_backward.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoder(x,hidden,cell,\n",
    "            wf,uf,bf,\n",
    "            wi,ui,bi,\n",
    "            wo,uo,bo,\n",
    "            wc,uc,bc,RRA):\n",
    "    \n",
    "    # LSTM with RRA\n",
    "    fg = tf.sigmoid( tf.matmul(x,wf) + tf.matmul(hidden,uf) + bf)\n",
    "    ig = tf.sigmoid( tf.matmul(x,wi) + tf.matmul(hidden,ui) + bi)\n",
    "    og = tf.sigmoid( tf.matmul(x,wo) + tf.matmul(hidden,uo) + bo)\n",
    "    cell_next = tf.multiply(fg,cell) + tf.multiply(ig,tf.sigmoid( tf.matmul(x,wc) + tf.matmul(hidden,uc) + bc))\n",
    "    hidden_next = tf.multiply(og,tf.tanh(cell+RRA))\n",
    "    \n",
    "    return hidden_next,cell_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(hs,ht,Wa,seq_len):\n",
    "    return tf.reshape(tf.matmul(tf.matmul(hs,Wa),tf.transpose(ht)),[seq_len])\n",
    "\n",
    "def align(hs,ht,Wp,Vp,Wa,tf_seq_len):\n",
    "   \n",
    "    pd = tf.TensorArray(size=(2*D+1),dtype=tf.float32)\n",
    "    \n",
    "    positions = tf.cast(tf_seq_len-1-2*D,dtype=tf.float32)\n",
    "    \n",
    "    sigmoid_multiplier = tf.nn.sigmoid(tf.matmul(tf.tanh(tf.matmul(ht,Wp)),Vp))\n",
    "    sigmoid_multiplier = tf.reshape(sigmoid_multiplier,[])\n",
    "    \n",
    "    pt_float = positions*sigmoid_multiplier\n",
    "    \n",
    "    pt = tf.cast(pt_float,tf.int32)\n",
    "    pt = pt+D #center to window\n",
    "    \n",
    "    sigma = tf.constant(D/2,dtype=tf.float32)\n",
    "    \n",
    "    i = 0\n",
    "    pos = pt - D\n",
    "    \n",
    "    def cond(i,pos,pd):\n",
    "        \n",
    "        return i < (2*D+1)\n",
    "                      \n",
    "    def body(i,pos,pd):\n",
    "        \n",
    "        comp_1 = tf.cast(tf.square(pos-pt),tf.float32)\n",
    "        comp_2 = tf.cast(2*tf.square(sigma),tf.float32)\n",
    "            \n",
    "        pd = pd.write(i,tf.exp(-(comp_1/comp_2)))\n",
    "            \n",
    "        return i+1,pos+1,pd\n",
    "                      \n",
    "    i,pos,pd = tf.while_loop(cond,body,[i,pos,pd])\n",
    "    \n",
    "    local_hs = hs[(pt-D):(pt+D+1)]\n",
    "    \n",
    "    normalized_scores = tf.nn.softmax(score(local_hs,ht,Wa,2*D+1))\n",
    "    \n",
    "    pd=pd.stack()\n",
    "    \n",
    "    G = tf.multiply(normalized_scores,pd)\n",
    "    G = tf.reshape(G,[2*D+1,1])\n",
    "    \n",
    "    return G,pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(tf_text,tf_seq_len,tf_output_len):\n",
    "    \n",
    "    #PARAMETERS\n",
    "    \n",
    "    #1.1 FORWARD ENCODER PARAMETERS\n",
    "    \n",
    "    initial_hidden_f = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    cell_f = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    wf_f = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    uf_f = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    bf_f = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    wi_f = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    ui_f = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    bi_f = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    wo_f = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    uo_f = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    bo_f = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    wc_f = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    uc_f = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    bc_f = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    Wattention_f = tf.Variable(tf.zeros([K,1]),dtype=tf.float32)\n",
    "                               \n",
    "    #1.2 BACKWARD ENCODER PARAMETERS\n",
    "    \n",
    "    initial_hidden_b = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    cell_b = tf.zeros([1,hidden_size],dtype=tf.float32)\n",
    "    wf_b = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    uf_b = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    bf_b = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    wi_b = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    ui_b = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    bi_b = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    wo_b = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    uo_b = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    bo_b = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    wc_b = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,hidden_size],stddev=0.01))\n",
    "    uc_b = tf.Variable(np.eye(hidden_size),dtype=tf.float32)\n",
    "    bc_b = tf.Variable(tf.zeros([1,hidden_size]),dtype=tf.float32)\n",
    "    Wattention_b = tf.Variable(tf.zeros([K,1]),dtype=tf.float32)\n",
    "    \n",
    "    #2 ATTENTION PARAMETERS\n",
    "    \n",
    "    Wp = tf.Variable(tf.truncated_normal(shape=[2*hidden_size,50],stddev=0.01))\n",
    "    Vp = tf.Variable(tf.truncated_normal(shape=[50,1],stddev=0.01))\n",
    "    Wa = tf.Variable(tf.truncated_normal(shape=[2*hidden_size,2*hidden_size],stddev=0.01))\n",
    "    Wc = tf.Variable(tf.truncated_normal(shape=[4*hidden_size,2*hidden_size],stddev=0.01))\n",
    "    \n",
    "    #3 DECODER PARAMETERS\n",
    "    \n",
    "    Ws = tf.Variable(tf.truncated_normal(shape=[2*hidden_size,vocab_len],stddev=0.01))\n",
    "    \n",
    "    cell_d = tf.zeros([1,2*hidden_size],dtype=tf.float32)\n",
    "    wf_d = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,2*hidden_size],stddev=0.01))\n",
    "    uf_d = tf.Variable(np.eye(2*hidden_size),dtype=tf.float32)\n",
    "    bf_d = tf.Variable(tf.zeros([1,2*hidden_size]),dtype=tf.float32)\n",
    "    wi_d = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,2*hidden_size],stddev=0.01))\n",
    "    ui_d = tf.Variable(np.eye(2*hidden_size),dtype=tf.float32)\n",
    "    bi_d = tf.Variable(tf.zeros([1,2*hidden_size]),dtype=tf.float32)\n",
    "    wo_d = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,2*hidden_size],stddev=0.01))\n",
    "    uo_d = tf.Variable(np.eye(2*hidden_size),dtype=tf.float32)\n",
    "    bo_d = tf.Variable(tf.zeros([1,2*hidden_size]),dtype=tf.float32)\n",
    "    wc_d = tf.Variable(tf.truncated_normal(shape=[word_vec_dim,2*hidden_size],stddev=0.01))\n",
    "    uc_d = tf.Variable(np.eye(2*hidden_size),dtype=tf.float32)\n",
    "    bc_d = tf.Variable(tf.zeros([1,2*hidden_size]),dtype=tf.float32)\n",
    "    \n",
    "    hidden_residuals_d = tf.TensorArray(size=K,dynamic_size=True,dtype=tf.float32,clear_after_read=False)\n",
    "    hidden_residuals_d = hidden_residuals_d.unstack(tf.zeros([K,2*hidden_size],dtype=tf.float32))\n",
    "    \n",
    "    Wattention_d = tf.Variable(tf.zeros([K,1]),dtype=tf.float32)\n",
    "    \n",
    "    output = tf.TensorArray(size=tf_output_len,dtype=tf.float32)\n",
    "                               \n",
    "    #BI-DIRECTIONAL LSTM\n",
    "                               \n",
    "    hidden_forward = forward_encoder(tf_text,\n",
    "                                     initial_hidden_f,cell_f,\n",
    "                                     wf_f,uf_f,bf_f,\n",
    "                                     wi_f,ui_f,bi_f,\n",
    "                                     wo_f,uo_f,bo_f,\n",
    "                                     wc_f,uc_f,bc_f,\n",
    "                                     Wattention_f,\n",
    "                                     tf_seq_len,\n",
    "                                     word_vec_dim)\n",
    "    \n",
    "    hidden_backward = backward_encoder(tf_text,\n",
    "                                     initial_hidden_b,cell_b,\n",
    "                                     wf_b,uf_b,bf_b,\n",
    "                                     wi_b,ui_b,bi_b,\n",
    "                                     wo_b,uo_b,bo_b,\n",
    "                                     wc_b,uc_b,bc_b,\n",
    "                                     Wattention_b,\n",
    "                                     tf_seq_len,\n",
    "                                     word_vec_dim)\n",
    "    \n",
    "    encoded_hidden = tf.concat([hidden_forward,hidden_backward],1)\n",
    "    \n",
    "    #ATTENTION MECHANISM AND DECODER\n",
    "    \n",
    "    decoded_hidden = encoded_hidden[0]\n",
    "    decoded_hidden = tf.reshape(decoded_hidden,[1,2*hidden_size])\n",
    "    Wattention_d_normalized = tf.nn.softmax(Wattention_d)\n",
    "    tf_embd_limit = tf.convert_to_tensor(np_embd_limit)\n",
    "    \n",
    "    y = tf.convert_to_tensor(SOS) #inital decoder token <SOS> vector\n",
    "    y = tf.reshape(y,[1,word_vec_dim])\n",
    "    \n",
    "    j=K\n",
    "    \n",
    "    hidden_residuals_stack = hidden_residuals_d.stack()\n",
    "    \n",
    "    RRA = tf.reduce_sum(tf.multiply(hidden_residuals_stack[j-K:j],Wattention_d_normalized),0)\n",
    "    RRA = tf.reshape(RRA,[1,2*hidden_size])\n",
    "    \n",
    "    decoded_hidden_next,cell_d = decoder(y,decoded_hidden,cell_d,\n",
    "                                  wf_d,uf_d,bf_d,\n",
    "                                  wi_d,ui_d,bf_d,\n",
    "                                  wo_d,uo_d,bf_d,\n",
    "                                  wc_d,uc_d,bc_d,\n",
    "                                  RRA)\n",
    "    decoded_hidden = decoded_hidden_next\n",
    "    \n",
    "    hidden_residuals_d = hidden_residuals_d.write(j,tf.reshape(decoded_hidden,[2*hidden_size]))\n",
    "    \n",
    "    j=j+1\n",
    "                           \n",
    "    i=0\n",
    "    \n",
    "    def attention_decoder_cond(i,j,decoded_hidden,cell_d,hidden_residuals_d,output):\n",
    "        return i < tf_output_len\n",
    "    \n",
    "    def attention_decoder_body(i,j,decoded_hidden,cell_d,hidden_residuals_d,output):\n",
    "        \n",
    "        #LOCAL ATTENTION\n",
    "        \n",
    "        G,pt = align(encoded_hidden,decoded_hidden,Wp,Vp,Wa,tf_seq_len)\n",
    "        local_encoded_hidden = encoded_hidden[pt-D:pt+D+1]\n",
    "        weighted_encoded_hidden = tf.multiply(local_encoded_hidden,G)\n",
    "        context_vector = tf.reduce_sum(weighted_encoded_hidden,0)\n",
    "        context_vector = tf.reshape(context_vector,[1,2*hidden_size])\n",
    "        \n",
    "        attended_hidden = tf.tanh(tf.matmul(tf.concat([context_vector,decoded_hidden],1),Wc))\n",
    "        \n",
    "        #DECODER\n",
    "        \n",
    "        y = tf.matmul(attended_hidden,Ws)\n",
    "        \n",
    "        output = output.write(i,tf.reshape(y,[vocab_len]))\n",
    "        #Save probability distribution as output\n",
    "        \n",
    "        y = tf.nn.softmax(y)\n",
    "        \n",
    "        y_index = tf.cast(tf.argmax(tf.reshape(y,[vocab_len])),tf.int32)\n",
    "        y = tf_embd_limit[y_index]\n",
    "        y = tf.reshape(y,[1,word_vec_dim])\n",
    "        \n",
    "        #setting next decoder input token as the word_vector of maximum probability \n",
    "        #as found from previous attention-decoder output.\n",
    "        \n",
    "        hidden_residuals_stack = hidden_residuals_d.stack()\n",
    "        \n",
    "        RRA = tf.reduce_sum(tf.multiply(hidden_residuals_stack[j-K:j],Wattention_d_normalized),0)\n",
    "        RRA = tf.reshape(RRA,[1,2*hidden_size])\n",
    "        \n",
    "        decoded_hidden_next,cell_d = decoder(y,decoded_hidden,cell_d,\n",
    "                                  wf_d,uf_d,bf_d,\n",
    "                                  wi_d,ui_d,bf_d,\n",
    "                                  wo_d,uo_d,bf_d,\n",
    "                                  wc_d,uc_d,bc_d,\n",
    "                                  RRA)\n",
    "        \n",
    "        decoded_hidden = decoded_hidden_next\n",
    "        \n",
    "        hidden_residuals_d = tf.cond(tf.equal(j,tf_output_len-1+K+1), #(+1 for <SOS>)\n",
    "                                   lambda: hidden_residuals_d,\n",
    "                                   lambda: hidden_residuals_d.write(j,tf.reshape(decoded_hidden,[2*hidden_size])))\n",
    "        \n",
    "        return i+1,j+1,decoded_hidden,cell_d,hidden_residuals_d,output\n",
    "    \n",
    "    i,j,decoded_hidden,cell_d,hidden_residuals_d,output = tf.while_loop(attention_decoder_cond,\n",
    "                                            attention_decoder_body,\n",
    "                                            [i,j,decoded_hidden,cell_d,hidden_residuals_d,output])\n",
    "    hidden_residuals_d.close().mark_used()\n",
    "    \n",
    "    output = output.stack()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = model(tf_text,tf_seq_len,tf_output_len)\n",
    "\n",
    "#OPTIMIZER\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=tf_summary))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#PREDICTION\n",
    "\n",
    "pred = tf.TensorArray(size=tf_output_len,dtype=tf.int32)\n",
    "\n",
    "i=0\n",
    "\n",
    "def cond_pred(i,pred):\n",
    "    return i<tf_output_len\n",
    "def body_pred(i,pred):\n",
    "    pred = pred.write(i,tf.cast(tf.argmax(output[i]),tf.int32))\n",
    "    return i+1,pred\n",
    "\n",
    "i,pred = tf.while_loop(cond_pred,body_pred,[i,pred]) \n",
    "\n",
    "prediction = pred.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0\n",
      "Training input sequence length: 59\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "unk proposal seeks to demonstrate a technique for observing ocean currents by electric field measurements using a towed instrument of recent design unk measurements will be made in conjunction with a cruise across the unk unk in which several additional observational techniques will be employed unk several data types will be unk to improve the accuracy of the methods\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "exceptional geology goal inviscid\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "loss=8.67275\n",
      "\n",
      "Iteration: 1\n",
      "Training input sequence length: 58\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk barotropic component of oceanic flow can be extracted from electric field measurements within the water column unk project will develop the capability of adding the measurement of weak electric fields to unk floats an existing neutrally buoyant subsurface float unk spatial distribution of barotropic currents would then be obtained along unk paths as they floated at depth\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk from unk unk\n",
      "\n",
      "loss=3.06275\n",
      "\n",
      "Iteration: 2\n",
      "Training input sequence length: 61\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk studies often shed light on oceanic processes unk unk has conducted a number of layered model experiments and has used the results to interpret ocean dynamics unk project is to construct a facility to perform continuously stratified fluid experiments under the influence of flow contractions unk obvious example of such a process is the flow through the unk of unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk and unk unk unk\n",
      "\n",
      "loss=2.33238\n",
      "\n",
      "Iteration: 3\n",
      "Training input sequence length: 67\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk role of coastal upwelling fronts and jets in general coastal circulation will be examined through numerical experiments on a supercomputer using a unk unk unk numerical model unk unk exchange may be inhibited or enhanced in the presence of fronts and this project will lead to insight about the conditions that favor each process unk the time scales for various mesoscale frontal features will be described\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk of unk unk and unk\n",
      "\n",
      "loss=3.65155\n",
      "\n",
      "Iteration: 4\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk in theoretical elementary particle physics will include work on the nature of spontaneous symmetry breaking supersymmetry string theory conformal quantum field theory and the problem of the confinement of quarks and unk unk research involves creative approaches to centrally important problems in elementary particle theory\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk in unk unk unk unk\n",
      "\n",
      "loss=2.72646\n",
      "\n",
      "Iteration: 5\n",
      "Training input sequence length: 62\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk goal of this research is to develop a methodology for programming in unk the most developed programming language based on logic programming in order to build moderately sized software unk methodology will be based on recognizing the key programming cliches and basic building blocks of writing unk and more importantly providing methods and tools for combining building blocks into complicated programs\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk for unk unk\n",
      "\n",
      "loss=2.55072\n",
      "\n",
      "Iteration: 6\n",
      "Training input sequence length: 48\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk will undertake graduate study in unk under the unk unk unk unk unk unk program provides unk support for those persons who have demonstrated ability and special aptitude for advanced training in engineering and who received unk unk in unk in the unk unk unk unk unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "loss=0.046375\n",
      "\n",
      "Iteration: 7\n",
      "Training input sequence length: 60\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk grant will support unk unk work in computational geometry for robot motion planning under uncertainty unk problem domains include limited visibility range unknown environments and terrain regions offering different traversal costs unk goals include unk path planning unk watchman and sweeper route planning and scheduling of surveillance tours with multiple watchmen under a variety of coordination and optimization criteria\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk and unk unk\n",
      "\n",
      "loss=0.7424\n",
      "\n",
      "Iteration: 8\n",
      "Training input sequence length: 79\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "unk this project a team of 3 unk unk will collaborate with collaborators from several other countries to deploy an array of surface drifters in the equatorial unk in support of the unk unk unk and unk unk unk unk drifters will provide data on surface and subsurface temperature and surface currents unk goals are to map unk unk unk unk and currents understand processes responsible for annual and interannual variability in unk and improve operational unk unk models\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "loss=0.367103\n",
      "\n",
      "Iteration: 9\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career in ocean sciences\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.347719\n",
      "\n",
      "Iteration: 10\n",
      "Training input sequence length: 63\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences with special emphasis on nutrient unk energy transformations crustacean larval biology and hydrocarbon contamination in the marine environment to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career of research\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.100135\n",
      "\n",
      "Iteration: 11\n",
      "Training input sequence length: 31\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk action is for the continuation of a program that has been outstanding in recruiting and involving women and minority students from the local area in significant and timely research projects\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk in unk unk\n",
      "\n",
      "loss=1.80866\n",
      "\n",
      "Iteration: 0\n",
      "Training input sequence length: 59\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "unk proposal seeks to demonstrate a technique for observing ocean currents by electric field measurements using a towed instrument of recent design unk measurements will be made in conjunction with a cruise across the unk unk in which several additional observational techniques will be employed unk several data types will be unk to improve the accuracy of the methods\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "loss=0.00799112\n",
      "\n",
      "Iteration: 1\n",
      "Training input sequence length: 58\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk barotropic component of oceanic flow can be extracted from electric field measurements within the water column unk project will develop the capability of adding the measurement of weak electric fields to unk floats an existing neutrally buoyant subsurface float unk spatial distribution of barotropic currents would then be obtained along unk paths as they floated at depth\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk from unk unk\n",
      "\n",
      "loss=1.24505\n",
      "\n",
      "Iteration: 2\n",
      "Training input sequence length: 61\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk studies often shed light on oceanic processes unk unk has conducted a number of layered model experiments and has used the results to interpret ocean dynamics unk project is to construct a facility to perform continuously stratified fluid experiments under the influence of flow contractions unk obvious example of such a process is the flow through the unk of unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk and unk unk unk\n",
      "\n",
      "loss=1.41425\n",
      "\n",
      "Iteration: 3\n",
      "Training input sequence length: 67\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk role of coastal upwelling fronts and jets in general coastal circulation will be examined through numerical experiments on a supercomputer using a unk unk unk numerical model unk unk exchange may be inhibited or enhanced in the presence of fronts and this project will lead to insight about the conditions that favor each process unk the time scales for various mesoscale frontal features will be described\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk of unk unk and unk\n",
      "\n",
      "loss=1.76168\n",
      "\n",
      "Iteration: 4\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk in theoretical elementary particle physics will include work on the nature of spontaneous symmetry breaking supersymmetry string theory conformal quantum field theory and the problem of the confinement of quarks and unk unk research involves creative approaches to centrally important problems in elementary particle theory\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk in unk unk unk unk\n",
      "\n",
      "loss=0.544461\n",
      "\n",
      "Iteration: 5\n",
      "Training input sequence length: 62\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk goal of this research is to develop a methodology for programming in unk the most developed programming language based on logic programming in order to build moderately sized software unk methodology will be based on recognizing the key programming cliches and basic building blocks of writing unk and more importantly providing methods and tools for combining building blocks into complicated programs\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk for unk unk\n",
      "\n",
      "loss=1.52153\n",
      "\n",
      "Iteration: 6\n",
      "Training input sequence length: 48\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk will undertake graduate study in unk under the unk unk unk unk unk unk program provides unk support for those persons who have demonstrated ability and special aptitude for advanced training in engineering and who received unk unk in unk in the unk unk unk unk unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "loss=0.514047\n",
      "\n",
      "Iteration: 7\n",
      "Training input sequence length: 60\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk grant will support unk unk work in computational geometry for robot motion planning under uncertainty unk problem domains include limited visibility range unknown environments and terrain regions offering different traversal costs unk goals include unk path planning unk watchman and sweeper route planning and scheduling of surveillance tours with multiple watchmen under a variety of coordination and optimization criteria\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk and unk unk\n",
      "\n",
      "loss=1.07789\n",
      "\n",
      "Iteration: 8\n",
      "Training input sequence length: 79\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "unk this project a team of 3 unk unk will collaborate with collaborators from several other countries to deploy an array of surface drifters in the equatorial unk in support of the unk unk unk and unk unk unk unk drifters will provide data on surface and subsurface temperature and surface currents unk goals are to map unk unk unk unk and currents understand processes responsible for annual and interannual variability in unk and improve operational unk unk models\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "loss=0.0784575\n",
      "\n",
      "Iteration: 9\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career in ocean sciences\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.0614352\n",
      "\n",
      "Iteration: 10\n",
      "Training input sequence length: 63\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences with special emphasis on nutrient unk energy transformations crustacean larval biology and hydrocarbon contamination in the marine environment to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career of research\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.0560612\n",
      "\n",
      "Iteration: 11\n",
      "Training input sequence length: 31\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk action is for the continuation of a program that has been outstanding in recruiting and involving women and minority students from the local area in significant and timely research projects\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk in unk unk\n",
      "\n",
      "loss=1.66718\n",
      "\n",
      "Iteration: 0\n",
      "Training input sequence length: 59\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "unk proposal seeks to demonstrate a technique for observing ocean currents by electric field measurements using a towed instrument of recent design unk measurements will be made in conjunction with a cruise across the unk unk in which several additional observational techniques will be employed unk several data types will be unk to improve the accuracy of the methods\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "loss=0.0428589\n",
      "\n",
      "Iteration: 1\n",
      "Training input sequence length: 58\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk barotropic component of oceanic flow can be extracted from electric field measurements within the water column unk project will develop the capability of adding the measurement of weak electric fields to unk floats an existing neutrally buoyant subsurface float unk spatial distribution of barotropic currents would then be obtained along unk paths as they floated at depth\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk from unk unk\n",
      "\n",
      "loss=0.971208\n",
      "\n",
      "Iteration: 2\n",
      "Training input sequence length: 61\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk studies often shed light on oceanic processes unk unk has conducted a number of layered model experiments and has used the results to interpret ocean dynamics unk project is to construct a facility to perform continuously stratified fluid experiments under the influence of flow contractions unk obvious example of such a process is the flow through the unk of unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk and unk unk unk\n",
      "\n",
      "loss=0.787202\n",
      "\n",
      "Iteration: 3\n",
      "Training input sequence length: 67\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk role of coastal upwelling fronts and jets in general coastal circulation will be examined through numerical experiments on a supercomputer using a unk unk unk numerical model unk unk exchange may be inhibited or enhanced in the presence of fronts and this project will lead to insight about the conditions that favor each process unk the time scales for various mesoscale frontal features will be described\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk of unk unk and unk\n",
      "\n",
      "loss=1.99665\n",
      "\n",
      "Iteration: 4\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk in theoretical elementary particle physics will include work on the nature of spontaneous symmetry breaking supersymmetry string theory conformal quantum field theory and the problem of the confinement of quarks and unk unk research involves creative approaches to centrally important problems in elementary particle theory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk in unk unk unk unk\n",
      "\n",
      "loss=1.69771\n",
      "\n",
      "Iteration: 5\n",
      "Training input sequence length: 62\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk goal of this research is to develop a methodology for programming in unk the most developed programming language based on logic programming in order to build moderately sized software unk methodology will be based on recognizing the key programming cliches and basic building blocks of writing unk and more importantly providing methods and tools for combining building blocks into complicated programs\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk for unk unk\n",
      "\n",
      "loss=0.985265\n",
      "\n",
      "Iteration: 6\n",
      "Training input sequence length: 48\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk will undertake graduate study in unk under the unk unk unk unk unk unk program provides unk support for those persons who have demonstrated ability and special aptitude for advanced training in engineering and who received unk unk in unk in the unk unk unk unk unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "loss=0.290561\n",
      "\n",
      "Iteration: 7\n",
      "Training input sequence length: 60\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk grant will support unk unk work in computational geometry for robot motion planning under uncertainty unk problem domains include limited visibility range unknown environments and terrain regions offering different traversal costs unk goals include unk path planning unk watchman and sweeper route planning and scheduling of surveillance tours with multiple watchmen under a variety of coordination and optimization criteria\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk and unk unk\n",
      "\n",
      "loss=0.612626\n",
      "\n",
      "Iteration: 8\n",
      "Training input sequence length: 79\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "unk this project a team of 3 unk unk will collaborate with collaborators from several other countries to deploy an array of surface drifters in the equatorial unk in support of the unk unk unk and unk unk unk unk drifters will provide data on surface and subsurface temperature and surface currents unk goals are to map unk unk unk unk and currents understand processes responsible for annual and interannual variability in unk and improve operational unk unk models\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "loss=0.0905202\n",
      "\n",
      "Iteration: 9\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career in ocean sciences\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.0516223\n",
      "\n",
      "Iteration: 10\n",
      "Training input sequence length: 63\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences with special emphasis on nutrient unk energy transformations crustacean larval biology and hydrocarbon contamination in the marine environment to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career of research\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.02705\n",
      "\n",
      "Iteration: 11\n",
      "Training input sequence length: 31\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk action is for the continuation of a program that has been outstanding in recruiting and involving women and minority students from the local area in significant and timely research projects\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk in unk unk\n",
      "\n",
      "loss=1.57751\n",
      "\n",
      "Iteration: 0\n",
      "Training input sequence length: 59\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "unk proposal seeks to demonstrate a technique for observing ocean currents by electric field measurements using a towed instrument of recent design unk measurements will be made in conjunction with a cruise across the unk unk in which several additional observational techniques will be employed unk several data types will be unk to improve the accuracy of the methods\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "loss=0.00722496\n",
      "\n",
      "Iteration: 1\n",
      "Training input sequence length: 58\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk barotropic component of oceanic flow can be extracted from electric field measurements within the water column unk project will develop the capability of adding the measurement of weak electric fields to unk floats an existing neutrally buoyant subsurface float unk spatial distribution of barotropic currents would then be obtained along unk paths as they floated at depth\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk from unk unk\n",
      "\n",
      "loss=1.10625\n",
      "\n",
      "Iteration: 2\n",
      "Training input sequence length: 61\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk studies often shed light on oceanic processes unk unk has conducted a number of layered model experiments and has used the results to interpret ocean dynamics unk project is to construct a facility to perform continuously stratified fluid experiments under the influence of flow contractions unk obvious example of such a process is the flow through the unk of unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk and unk unk unk\n",
      "\n",
      "loss=1.35571\n",
      "\n",
      "Iteration: 3\n",
      "Training input sequence length: 67\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk role of coastal upwelling fronts and jets in general coastal circulation will be examined through numerical experiments on a supercomputer using a unk unk unk numerical model unk unk exchange may be inhibited or enhanced in the presence of fronts and this project will lead to insight about the conditions that favor each process unk the time scales for various mesoscale frontal features will be described\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk of unk unk and unk\n",
      "\n",
      "loss=2.03553\n",
      "\n",
      "Iteration: 4\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk in theoretical elementary particle physics will include work on the nature of spontaneous symmetry breaking supersymmetry string theory conformal quantum field theory and the problem of the confinement of quarks and unk unk research involves creative approaches to centrally important problems in elementary particle theory\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk in unk unk unk unk\n",
      "\n",
      "loss=0.731751\n",
      "\n",
      "Iteration: 5\n",
      "Training input sequence length: 62\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk goal of this research is to develop a methodology for programming in unk the most developed programming language based on logic programming in order to build moderately sized software unk methodology will be based on recognizing the key programming cliches and basic building blocks of writing unk and more importantly providing methods and tools for combining building blocks into complicated programs\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk for unk unk\n",
      "\n",
      "loss=0.844648\n",
      "\n",
      "Iteration: 6\n",
      "Training input sequence length: 48\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk will undertake graduate study in unk under the unk unk unk unk unk unk program provides unk support for those persons who have demonstrated ability and special aptitude for advanced training in engineering and who received unk unk in unk in the unk unk unk unk unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "loss=0.489594\n",
      "\n",
      "Iteration: 7\n",
      "Training input sequence length: 60\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk grant will support unk unk work in computational geometry for robot motion planning under uncertainty unk problem domains include limited visibility range unknown environments and terrain regions offering different traversal costs unk goals include unk path planning unk watchman and sweeper route planning and scheduling of surveillance tours with multiple watchmen under a variety of coordination and optimization criteria\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk and unk unk\n",
      "\n",
      "loss=0.897257\n",
      "\n",
      "Iteration: 8\n",
      "Training input sequence length: 79\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "unk this project a team of 3 unk unk will collaborate with collaborators from several other countries to deploy an array of surface drifters in the equatorial unk in support of the unk unk unk and unk unk unk unk drifters will provide data on surface and subsurface temperature and surface currents unk goals are to map unk unk unk unk and currents understand processes responsible for annual and interannual variability in unk and improve operational unk unk models\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "loss=0.333288\n",
      "\n",
      "Iteration: 9\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career in ocean sciences\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.165122\n",
      "\n",
      "Iteration: 10\n",
      "Training input sequence length: 63\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences with special emphasis on nutrient unk energy transformations crustacean larval biology and hydrocarbon contamination in the marine environment to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career of research\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.0664452\n",
      "\n",
      "Iteration: 11\n",
      "Training input sequence length: 31\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk action is for the continuation of a program that has been outstanding in recruiting and involving women and minority students from the local area in significant and timely research projects\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk in unk unk\n",
      "\n",
      "loss=1.48027\n",
      "\n",
      "Iteration: 0\n",
      "Training input sequence length: 59\n",
      "Training target outputs sequence length: 4\n",
      "\n",
      "TEXT:\n",
      "unk proposal seeks to demonstrate a technique for observing ocean currents by electric field measurements using a towed instrument of recent design unk measurements will be made in conjunction with a cruise across the unk unk in which several additional observational techniques will be employed unk several data types will be unk to improve the accuracy of the methods\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk\n",
      "\n",
      "loss=0.0113897\n",
      "\n",
      "Iteration: 1\n",
      "Training input sequence length: 58\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk barotropic component of oceanic flow can be extracted from electric field measurements within the water column unk project will develop the capability of adding the measurement of weak electric fields to unk floats an existing neutrally buoyant subsurface float unk spatial distribution of barotropic currents would then be obtained along unk paths as they floated at depth\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk from unk unk\n",
      "\n",
      "loss=1.2222\n",
      "\n",
      "Iteration: 2\n",
      "Training input sequence length: 61\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk studies often shed light on oceanic processes unk unk has conducted a number of layered model experiments and has used the results to interpret ocean dynamics unk project is to construct a facility to perform continuously stratified fluid experiments under the influence of flow contractions unk obvious example of such a process is the flow through the unk of unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk and unk unk unk\n",
      "\n",
      "loss=1.16539\n",
      "\n",
      "Iteration: 3\n",
      "Training input sequence length: 67\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk role of coastal upwelling fronts and jets in general coastal circulation will be examined through numerical experiments on a supercomputer using a unk unk unk numerical model unk unk exchange may be inhibited or enhanced in the presence of fronts and this project will lead to insight about the conditions that favor each process unk the time scales for various mesoscale frontal features will be described\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk of unk unk and unk\n",
      "\n",
      "loss=1.86123\n",
      "\n",
      "Iteration: 4\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk in theoretical elementary particle physics will include work on the nature of spontaneous symmetry breaking supersymmetry string theory conformal quantum field theory and the problem of the confinement of quarks and unk unk research involves creative approaches to centrally important problems in elementary particle theory\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk in unk unk unk unk\n",
      "\n",
      "loss=1.54924\n",
      "\n",
      "Iteration: 5\n",
      "Training input sequence length: 62\n",
      "Training target outputs sequence length: 7\n",
      "\n",
      "TEXT:\n",
      "unk goal of this research is to develop a methodology for programming in unk the most developed programming language based on logic programming in order to build moderately sized software unk methodology will be based on recognizing the key programming cliches and basic building blocks of writing unk and more importantly providing methods and tools for combining building blocks into complicated programs\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk for unk unk\n",
      "\n",
      "loss=1.14848\n",
      "\n",
      "Iteration: 6\n",
      "Training input sequence length: 48\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk will undertake graduate study in unk under the unk unk unk unk unk unk program provides unk support for those persons who have demonstrated ability and special aptitude for advanced training in engineering and who received unk unk in unk in the unk unk unk unk unk\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "loss=0.174314\n",
      "\n",
      "Iteration: 7\n",
      "Training input sequence length: 60\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk grant will support unk unk work in computational geometry for robot motion planning under uncertainty unk problem domains include limited visibility range unknown environments and terrain regions offering different traversal costs unk goals include unk path planning unk watchman and sweeper route planning and scheduling of surveillance tours with multiple watchmen under a variety of coordination and optimization criteria\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk and unk unk\n",
      "\n",
      "loss=0.529724\n",
      "\n",
      "Iteration: 8\n",
      "Training input sequence length: 79\n",
      "Training target outputs sequence length: 3\n",
      "\n",
      "TEXT:\n",
      "unk this project a team of 3 unk unk will collaborate with collaborators from several other countries to deploy an array of surface drifters in the equatorial unk in support of the unk unk unk and unk unk unk unk drifters will provide data on surface and subsurface temperature and surface currents unk goals are to map unk unk unk unk and currents understand processes responsible for annual and interannual variability in unk and improve operational unk unk models\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk\n",
      "\n",
      "loss=0.383329\n",
      "\n",
      "Iteration: 9\n",
      "Training input sequence length: 46\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career in ocean sciences\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.252159\n",
      "\n",
      "Iteration: 10\n",
      "Training input sequence length: 63\n",
      "Training target outputs sequence length: 6\n",
      "\n",
      "TEXT:\n",
      "unk award supports a unk unk for unk unk unk proposal to provide research experiences for selected undergraduates in marine sciences with special emphasis on nutrient unk energy transformations crustacean larval biology and hydrocarbon contamination in the marine environment to acquaint them with the excitement and opportunities of academic research and to encourage them to pursue graduates studies and a career of research\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk unk unk unk unk\n",
      "\n",
      "loss=0.10085\n",
      "\n",
      "Iteration: 11\n",
      "Training input sequence length: 31\n",
      "Training target outputs sequence length: 5\n",
      "\n",
      "TEXT:\n",
      "unk action is for the continuation of a program that has been outstanding in recruiting and involving women and minority students from the local area in significant and timely research projects\n",
      "\n",
      "\n",
      "PREDICTED SUMMARY:\n",
      "\n",
      "unk unk unk unk unk\n",
      "\n",
      "ACTUAL SUMMARY:\n",
      "\n",
      "unk unk in unk unk\n",
      "\n",
      "loss=1.252\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from __future__ import print_function\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "with tf.Session() as sess: # Start Tensorflow Session\n",
    "    \n",
    "    saver = tf.train.Saver() \n",
    "    # Prepares variable for saving the model\n",
    "    sess.run(init) #initialize all variables\n",
    "    step = 0   \n",
    "    loss_list=[]\n",
    "    acc_list=[]\n",
    "    val_loss_list=[]\n",
    "    val_acc_list=[]\n",
    "    best_val_acc=0\n",
    "    display_step = 1\n",
    "    \n",
    "    while step < training_iters:\n",
    "        \n",
    "        total_loss=0\n",
    "        total_acc=0\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "           \n",
    "        for i in range(0,train_len):\n",
    "            \n",
    "            train_out = transform_out(train_summaries[i][0:len(train_summaries[i])-1])\n",
    "            \n",
    "            if i%display_step==0:\n",
    "                print(\"\\nIteration: \"+str(i))\n",
    "                print(\"Training input sequence length: \"+str(len(train_texts[i])))\n",
    "                print(\"Training target outputs sequence length: \"+str(len(train_out)))\n",
    "            \n",
    "                print(\"\\nTEXT:\")\n",
    "                flag = 0\n",
    "                for vec in train_texts[i]:\n",
    "                    if vec2word(vec) in string.punctuation or flag==0:\n",
    "                        print(str(vec2word(vec)),end='')\n",
    "                    else:\n",
    "                        print((\" \"+str(vec2word(vec))),end='')\n",
    "                    flag=1\n",
    "\n",
    "                print(\"\\n\")\n",
    "\n",
    "\n",
    "            # Run optimization operation (backpropagation)\n",
    "            _,loss,pred = sess.run([optimizer,cost,prediction],feed_dict={tf_text: train_texts[i], \n",
    "                                                    tf_seq_len: len(train_texts[i]), \n",
    "                                                    tf_summary: train_out,\n",
    "                                                    tf_output_len: len(train_out)})\n",
    "            \n",
    "         \n",
    "            if i%display_step==0:\n",
    "                print(\"\\nPREDICTED SUMMARY:\\n\")\n",
    "                flag = 0\n",
    "                for index in pred:\n",
    "                    #if int(index)!=vocab_limit.index('eos'):\n",
    "                    if vocab_limit[int(index)] in string.punctuation or flag==0:\n",
    "                        print(str(vocab_limit[int(index)]),end='')\n",
    "                    else:\n",
    "                        print(\" \"+str(vocab_limit[int(index)]),end='')\n",
    "                    flag=1\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                print(\"ACTUAL SUMMARY:\\n\")\n",
    "                flag = 0\n",
    "                for vec in train_summaries[i]:\n",
    "                    if vec2word(vec)!='eos':\n",
    "                        if vec2word(vec) in string.punctuation or flag==0:\n",
    "                            print(str(vec2word(vec)),end='')\n",
    "                        else:\n",
    "                            print((\" \"+str(vec2word(vec))),end='')\n",
    "                    flag=1\n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(\"loss=\"+str(loss))\n",
    "            \n",
    "        step=step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
